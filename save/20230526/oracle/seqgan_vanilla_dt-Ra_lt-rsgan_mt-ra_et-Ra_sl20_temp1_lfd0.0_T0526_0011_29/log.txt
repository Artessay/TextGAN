====================================================================================================
> training arguments:
>>> if_test: 0
>>> run_model: seqgan
>>> k_label: 2
>>> dataset: oracle
>>> model_type: vanilla
>>> loss_type: rsgan
>>> mu_type: ragan
>>> eval_type: Ra
>>> d_type: Ra
>>> if_real_data: 0
>>> cuda: 1
>>> device: 0
>>> devices: 0
>>> shuffle: 0
>>> gen_init: normal
>>> dis_init: uniform
>>> n_parent: 1
>>> eval_b_num: 8
>>> lambda_fq: 1.0
>>> lambda_fd: 0.0
>>> d_out_mean: True
>>> freeze_dis: False
>>> freeze_clas: False
>>> use_all_real_fake: False
>>> use_population: False
>>> samples_num: 10000
>>> vocab_size: 5000
>>> mle_epoch: 120
>>> clas_pre_epoch: 10
>>> adv_epoch: 200
>>> inter_epoch: 15
>>> batch_size: 64
>>> max_seq_len: 20
>>> start_letter: 1
>>> padding_idx: 0
>>> gen_lr: 0.01
>>> gen_adv_lr: 0.0001
>>> dis_lr: 0.0001
>>> clip_norm: 5.0
>>> pre_log_step: 10
>>> adv_log_step: 1
>>> train_data: dataset/oracle.txt
>>> test_data: dataset/testdata/oracle_test.txt
>>> temp_adpt: exp
>>> evo_temp_step: 1
>>> temperature: 1
>>> ora_pretrain: 1
>>> gen_pretrain: 0
>>> dis_pretrain: 0
>>> adv_g_step: 1
>>> rollout_num: 16
>>> gen_embed_dim: 32
>>> gen_hidden_dim: 32
>>> goal_size: 16
>>> step_size: 4
>>> mem_slots: 1
>>> num_heads: 2
>>> head_size: 256
>>> d_step: 5
>>> d_epoch: 3
>>> adv_d_step: 4
>>> adv_d_epoch: 2
>>> dis_embed_dim: 64
>>> dis_hidden_dim: 64
>>> num_rep: 64
>>> use_nll_oracle: 1
>>> use_nll_gen: 1
>>> use_nll_div: 1
>>> use_bleu: 1
>>> use_self_bleu: 1
>>> use_clas_acc: True
>>> use_ppl: 0
>>> log_file: log/log_0526_0011_29.txt
>>> save_root: save/20230526/oracle/seqgan_vanilla_dt-Ra_lt-rsgan_mt-ra_et-Ra_sl20_temp1_lfd0.0_T0526_0011_29/
>>> signal_file: run_signal.txt
>>> tips: SeqGAN experiments
====================================================================================================
Starting Generator MLE Training...
[MLE-GEN] epoch 0 : pre_loss = 7.8458, NLL_oracle = 9.8039, NLL_gen = 7.7093, NLL_div = 7.7484
[MLE-GEN] epoch 10 : pre_loss = 7.0784, NLL_oracle = 9.1777, NLL_gen = 7.0694, NLL_div = 7.145
[MLE-GEN] epoch 20 : pre_loss = 6.7474, NLL_oracle = 9.0253, NLL_gen = 6.7674, NLL_div = 6.8044
[MLE-GEN] epoch 30 : pre_loss = 6.5792, NLL_oracle = 8.9536, NLL_gen = 6.6174, NLL_div = 6.5818
[MLE-GEN] epoch 40 : pre_loss = 6.4856, NLL_oracle = 8.9431, NLL_gen = 6.5132, NLL_div = 6.4589
[MLE-GEN] epoch 50 : pre_loss = 6.4167, NLL_oracle = 8.9265, NLL_gen = 6.4097, NLL_div = 6.3707
[MLE-GEN] epoch 60 : pre_loss = 6.3718, NLL_oracle = 8.9228, NLL_gen = 6.3185, NLL_div = 6.3137
[MLE-GEN] epoch 70 : pre_loss = 6.3330, NLL_oracle = 8.9155, NLL_gen = 6.2623, NLL_div = 6.267
[MLE-GEN] epoch 80 : pre_loss = 6.3018, NLL_oracle = 8.9133, NLL_gen = 6.2121, NLL_div = 6.2323
[MLE-GEN] epoch 90 : pre_loss = 6.2868, NLL_oracle = 8.9188, NLL_gen = 6.1828, NLL_div = 6.2078
[MLE-GEN] epoch 100 : pre_loss = 6.2571, NLL_oracle = 8.9041, NLL_gen = 6.1557, NLL_div = 6.1855
[MLE-GEN] epoch 110 : pre_loss = 6.2407, NLL_oracle = 8.9072, NLL_gen = 6.124, NLL_div = 6.1712
[MLE-GEN] epoch 119 : pre_loss = 6.2326, NLL_oracle = 8.914, NLL_gen = 6.1228, NLL_div = 6.1435
Starting Discriminator Training...
[MLE-DIS] d_step 0: d_loss = 0.6484, train_acc = 0.6527, eval_acc = 0.5449,
[MLE-DIS] d_step 1: d_loss = 0.1838, train_acc = 0.9584, eval_acc = 0.5410,
[MLE-DIS] d_step 2: d_loss = 0.0346, train_acc = 0.9992, eval_acc = 0.5176,
[MLE-DIS] d_step 3: d_loss = 0.0124, train_acc = 0.9999, eval_acc = 0.5156,
[MLE-DIS] d_step 4: d_loss = 0.0075, train_acc = 1.0000, eval_acc = 0.5195,
Starting Adversarial Training...
Initial generator: NLL_oracle = 8.9126, NLL_gen = 6.1228, NLL_div = 6.153
-----
ADV EPOCH 0
-----
[ADV-GEN]: g_loss = 692.5750, NLL_oracle = 8.8716, NLL_gen = 6.1254, NLL_div = 6.1338
[ADV-DIS] d_step 0: d_loss = 0.0114, train_acc = 0.9995, eval_acc = 0.5117,
[ADV-DIS] d_step 1: d_loss = 0.0077, train_acc = 0.9999, eval_acc = 0.5068,
[ADV-DIS] d_step 2: d_loss = 0.0066, train_acc = 0.9996, eval_acc = 0.5049,
[ADV-DIS] d_step 3: d_loss = 0.0051, train_acc = 0.9998, eval_acc = 0.5059,
-----
ADV EPOCH 1
-----
[ADV-GEN]: g_loss = 115.4657, NLL_oracle = 8.8528, NLL_gen = 6.1314, NLL_div = 6.1232
[ADV-DIS] d_step 0: d_loss = 0.0044, train_acc = 0.9998, eval_acc = 0.5098,
[ADV-DIS] d_step 1: d_loss = 0.0031, train_acc = 0.9999, eval_acc = 0.5068,
[ADV-DIS] d_step 2: d_loss = 0.0032, train_acc = 0.9999, eval_acc = 0.5049,
[ADV-DIS] d_step 3: d_loss = 0.0027, train_acc = 0.9998, eval_acc = 0.5049,
-----
ADV EPOCH 2
-----
[ADV-GEN]: g_loss = 59.3400, NLL_oracle = 8.8364, NLL_gen = 6.1384, NLL_div = 6.1154
[ADV-DIS] d_step 0: d_loss = 0.0026, train_acc = 0.9997, eval_acc = 0.5049,
[ADV-DIS] d_step 1: d_loss = 0.0019, train_acc = 0.9998, eval_acc = 0.5049,
[ADV-DIS] d_step 2: d_loss = 0.0013, train_acc = 0.9999, eval_acc = 0.5020,
[ADV-DIS] d_step 3: d_loss = 0.0016, train_acc = 0.9999, eval_acc = 0.5020,
-----
ADV EPOCH 3
-----
[ADV-GEN]: g_loss = 52.3612, NLL_oracle = 8.8177, NLL_gen = 6.1455, NLL_div = 6.1108
[ADV-DIS] d_step 0: d_loss = 0.0016, train_acc = 0.9999, eval_acc = 0.5000,
[ADV-DIS] d_step 1: d_loss = 0.0012, train_acc = 0.9999, eval_acc = 0.4980,
[ADV-DIS] d_step 2: d_loss = 0.0011, train_acc = 0.9999, eval_acc = 0.5000,
[ADV-DIS] d_step 3: d_loss = 0.0009, train_acc = 0.9999, eval_acc = 0.5010,
-----
ADV EPOCH 4
-----
[ADV-GEN]: g_loss = 22.8294, NLL_oracle = 8.8098, NLL_gen = 6.1527, NLL_div = 6.1014
[ADV-DIS] d_step 0: d_loss = 0.0014, train_acc = 0.9997, eval_acc = 0.4980,
[ADV-DIS] d_step 1: d_loss = 0.0008, train_acc = 0.9999, eval_acc = 0.5010,
[ADV-DIS] d_step 2: d_loss = 0.0013, train_acc = 0.9997, eval_acc = 0.5029,
